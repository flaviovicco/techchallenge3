# Tech Challenge 3 - 5IADT
Tech Challenge - Fase 3: Exemplo de Fine-Tuning de um foundation model (Llama, BERT, MISTRAL etc.), utilizando o dataset "The AmazonTitles-1.3MM"
da Pos Tech em IA para Devs da FIAP, 2025, conduzido pelo professor Carlos Arag√£o

Flavio Luiz Vicco - RM 361664

> Ol√°, pessoal! Eu sou o Flavio Vicco e hoje vou apresentar o Tech Challenge da Fase 3 da Pos Tech em IA para Devs da FIAP, 2025, conduzido pelo professor Carlos Arag√£o. Vou mostrar como desenvolvi um pipeline completo de fine-tuning de um modelo de linguagem para gerar resumos autom√°ticos de produtos da Amazon. Vamos entender como o programa funciona, desde o pr√©-processamento dos dados at√© o treinamento e avalia√ß√£o do modelo.

# üß© Resumo da l√≥gica de fine-tuning

### 1Ô∏è‚É£ Limpeza e formata√ß√£o dos dados: transforma o dataset original em pares input ‚Üí resumo.

### 2Ô∏è‚É£ Gera√ß√£o autom√°tica de r√≥tulos (resumos): usa um modelo pr√©-treinado (BART) para gerar exemplos de sa√≠da.

### 3Ô∏è‚É£ Tokeniza√ß√£o: converte textos em IDs para o modelo T5.

### 4Ô∏è‚É£ Treinamento (fine-tuning): ajusta o modelo t5-base para aprender a resumir descri√ß√µes de produtos.

### 5Ô∏è‚É£ Avalia√ß√£o: mede a qualidade dos resumos com a m√©trica ROUGE.

### 6Ô∏è‚É£ Valida√ß√£o manual: testa o modelo em exemplos conhecidos e novos.

### 7Ô∏è‚É£ Salvamento e reuso: salva o modelo afinado para uso futuro.
