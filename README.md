# Tech Challenge 3 - 5IADT
Tech Challenge - Fase 3: Exemplo de Fine-Tuning de um foundation model (Llama, BERT, MISTRAL etc.), utilizando o dataset "The AmazonTitles-1.3MM"
da Pos Tech em IA para Devs da FIAP, 2025, conduzido pelo professor Carlos Arag√£o

Flavio Luiz Vicco - RM 361664

https://youtu.be/RQl69dSBtao

> Ol√°, pessoal! Eu sou o Flavio Vicco e hoje vou apresentar o Tech Challenge da Fase 3 da Pos Tech em IA para Devs da FIAP, 2025, conduzido pelo professor Carlos Arag√£o. Vou mostrar como desenvolvi um pipeline completo de fine-tuning de um modelo de linguagem para gerar resumos autom√°ticos de produtos da Amazon. Vamos entender como o programa funciona, desde o pr√©-processamento dos dados at√© o treinamento e avalia√ß√£o do modelo.

# ‚öôÔ∏è Resumo da l√≥gica de fine-tuning

### üì¶ 1Ô∏è‚É£ Carregamento, limpeza e formata√ß√£o dos dados: transforma o dataset original em pares input ‚Üí resumo.
A primeira etapa √© a base de tudo: preparar os dados.
O programa l√™ um arquivo JSON contendo descri√ß√µes de produtos.
Para otimizar o uso de mem√≥ria, ele limita a leitura aos cem mil primeiros registros.
Depois, o c√≥digo cria um DataFrame com apenas as colunas importantes: o t√≠tulo e a descri√ß√£o do produto.
Linhas vazias ou duplicadas s√£o removidas, garantindo que o modelo aprenda apenas com informa√ß√µes relevantes.

<img width="234" height="131" alt="image" src="https://github.com/user-attachments/assets/53aa07e4-54b2-4bba-8c07-071c5d5b812a" />

### ‚úèÔ∏è 2Ô∏è‚É£ Exportar o Dataset limpo
Com o conjunto de dados limpo, o pr√≥ximo passo √© salvar tudo em formato JSONL ‚Äî
um formato onde cada linha √© um registro independente.
Isso facilita o processamento de grandes volumes e √© o padr√£o usado em treinamento nos modelos na OpenAI e Hugging Face.

<img width="256" height="26" alt="image" src="https://github.com/user-attachments/assets/b411e27d-cc30-4145-8d9d-4d747d2f2b93" />

### ü§ñ 3Ô∏è‚É£ Gera√ß√£o de resumos autom√°ticos com BART para gerar exemplos de sa√≠da.
Agora come√ßa a parte interessante!
Antes de treinar o modelo, precisamos de exemplos de entrada e sa√≠da ‚Äî ou seja, textos e seus resumos.
Aqui usamos o modelo facebook/bart-large-cnn, um modelo pr√©-treinado da Hugging Face, para gerar automaticamente os resumos iniciais.
A fun√ß√£o grava os resultados incrementalmente, economizando mem√≥ria

### üß† 4Ô∏è‚É£ Prepara√ß√£o do dataset para fine-tuning
Com os resumos prontos, criamos o dataset final para o fine-tuning.
O programa l√™ o arquivo de resumos e monta pares input ‚Üí output,
onde o input cont√©m o t√≠tulo e a descri√ß√£o, e o output √© o resumo gerado.
O texto come√ßa com o prefixo ‚Äòsummarize:‚Äô, que ajuda o modelo T5 a entender a tarefa.

### üî§ 5Ô∏è‚É£ Tokeniza√ß√£o: converte textos em IDs para o modelo T5.
A pr√≥xima etapa √© converter os textos em tokens.
Usamos o tokenizer do modelo T5-base, limitando o tamanho m√°ximo de entrada e sa√≠da.
Isso prepara o dataset para ser processado pela rede neural

### üß© 6Ô∏è‚É£ Treinamento (fine-tuning): ajusta o modelo t5-base para aprender a resumir descri√ß√µes de produtos.
Aqui acontece o fine-tuning de verdade!
O modelo T5-base √© carregado e treinado com nossos dados.
Definimos hiperpar√¢metros como n√∫mero de √©pocas, tamanho do batch e diret√≥rio de logs.
Usamos a m√©trica ROUGE, que mede a similaridade entre o resumo gerado e o real.

<img width="904" height="153" alt="image" src="https://github.com/user-attachments/assets/4935d5ca-6b44-4ec0-9420-c4a0f86efe54" />

### üß™ 7Ô∏è‚É£ Avalia√ß√£o: mede a qualidade dos resumos com a m√©trica ROUGE.
Ap√≥s o treinamento, testamos o modelo com exemplos reais.
O c√≥digo gera novos resumos e imprime o resultado decodificado.
Primeiro testamos manualmente alguns produtos.
Depois, avaliamos automaticamente usando o ROUGE ‚Äî que nos d√° um valor num√©rico da qualidade do resumo

<img width="1810" height="476" alt="image" src="https://github.com/user-attachments/assets/568756eb-8eba-4ff6-913b-f4f41052d741" />

### üíæ 8Ô∏è‚É£ Salvamento e reuso: salva o modelo afinado para uso futuro.
Por fim, o modelo √© salvo e recarregado para valida√ß√£o.
Primeiro testamos manualmente alguns produtos.
Depois, avaliamos automaticamente usando o ROUGE ‚Äî que nos d√° um valor num√©rico da qualidade do resumo.
